{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, iirnotch, lfilter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "\n",
    "#Extracting the data from the \n",
    "data_set_path = \"D:\\Downloads\\WESAD\\WESAD\\\\\"\n",
    "subject = [\"S2\",'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17']\n",
    "\n",
    "class read_data_of_one_subject:\n",
    "    \"\"\"Read data from WESAD dataset\"\"\"\n",
    "    def __init__(self, path, subject):\n",
    "        self.keys = ['label', 'subject', 'signal']\n",
    "        self.signal_keys = ['wrist', 'chest']\n",
    "        self.chest_sensor_keys = ['ACC', 'ECG', 'EDA', 'EMG', 'Resp', 'Temp']\n",
    "        self.wrist_sensor_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        #os.chdir(path)\n",
    "        #os.chdir(subject)\n",
    "        with open(path + subject +'/'+subject + '.pkl', 'rb') as file:\n",
    "            data = pickle.load(file, encoding='latin1')\n",
    "        self.data = data\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.data[self.keys[0]]\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        #label = self.data[self.keys[0]]\n",
    "        assert subject == self.data[self.keys[1]]\n",
    "        signal = self.data[self.keys[2]]\n",
    "        wrist_data = signal[self.signal_keys[0]]\n",
    "        #wrist_ACC = wrist_data[self.wrist_sensor_keys[0]]\n",
    "        #wrist_ECG = wrist_data[self.wrist_sensor_keys[1]]\n",
    "        return wrist_data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        signal = self.data[self.keys[2]]\n",
    "        chest_data = signal[self.signal_keys[1]]\n",
    "        return chest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:474: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:351: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\complexity\\optim_complexity_k.py:134: RuntimeWarning: divide by zero encountered in divide\n",
      "  normalization = (n - 1) / (np.floor((n - k_subrange) / k).astype(int) * k)\n",
      "c:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\complexity\\optim_complexity_k.py:135: RuntimeWarning: invalid value encountered in multiply\n",
      "  sets = (np.nansum(np.abs(np.diff(sig_values)), axis=1) * normalization) / k\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m peaks_b, info \u001b[39m=\u001b[39m ECG_feat_base\u001b[39m.\u001b[39mrpeaks()\n\u001b[0;32m     67\u001b[0m peaks_s, info \u001b[39m=\u001b[39m ECG_feat_stress\u001b[39m.\u001b[39mrpeaks()\n\u001b[1;32m---> 68\u001b[0m hrv_b\u001b[39m=\u001b[39m ECG_feat_base\u001b[39m.\u001b[39;49mHRV(peaks_b, fs)\n\u001b[0;32m     69\u001b[0m hrv_s\u001b[39m=\u001b[39m ECG_feat_stress\u001b[39m.\u001b[39mHRV(peaks_s, fs)\n\u001b[0;32m     71\u001b[0m \u001b[39m# eda_features = np.vstack((ecg_features,ecg_feat_s))\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m# eda_features = np.vstack((ecg_features,ecg_feat_b))\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\GitHub\\EPO-4_BioBombs\\Machine learning\\ECG.py:152\u001b[0m, in \u001b[0;36mECGfeatures.HRV\u001b[1;34m(self, signal, title)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mHRV\u001b[39m(\u001b[39mself\u001b[39m, signal, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    147\u001b[0m     \u001b[39m#if signal==[]:\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[39m#    signal=self.ecg\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     \u001b[39m#    print(\"yes\")\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[39m#else:\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[39m#    print(\"No\")\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     HRV\u001b[39m=\u001b[39mnk\u001b[39m.\u001b[39;49mhrv(signal, sampling_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFs)\n\u001b[0;32m    153\u001b[0m     \u001b[39m# if title==\"\":\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[39m#     title=self.title\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[39m# plt.plot((rpeaks['ECG_R_Peaks']/self.Fs),self.ecg[rpeaks['ECG_R_Peaks']], 'go')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39m# plt.ylabel('$ECG$') \u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m HRV\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\hrv\\hrv.py:107\u001b[0m, in \u001b[0;36mhrv\u001b[1;34m(peaks, sampling_rate, show, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m out\u001b[39m.\u001b[39mappend(hrv_time(peaks, sampling_rate\u001b[39m=\u001b[39msampling_rate))\n\u001b[0;32m    106\u001b[0m out\u001b[39m.\u001b[39mappend(hrv_frequency(peaks, sampling_rate\u001b[39m=\u001b[39msampling_rate))\n\u001b[1;32m--> 107\u001b[0m out\u001b[39m.\u001b[39mappend(hrv_nonlinear(peaks, sampling_rate\u001b[39m=\u001b[39;49msampling_rate))\n\u001b[0;32m    109\u001b[0m \u001b[39m# Compute RSA if rsp data is available\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(peaks, pd\u001b[39m.\u001b[39mDataFrame):\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:245\u001b[0m, in \u001b[0;36mhrv_nonlinear\u001b[1;34m(peaks, sampling_rate, show, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m out[\u001b[39m\"\u001b[39m\u001b[39mRCMSEn\u001b[39m\u001b[39m\"\u001b[39m], _ \u001b[39m=\u001b[39m entropy_multiscale(rri, dimension\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, tolerance\u001b[39m=\u001b[39mtolerance, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRCMSEn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m out[\u001b[39m\"\u001b[39m\u001b[39mCD\u001b[39m\u001b[39m\"\u001b[39m], _ \u001b[39m=\u001b[39m fractal_correlation(rri, delay\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, dimension\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 245\u001b[0m out[\u001b[39m\"\u001b[39m\u001b[39mHFD\u001b[39m\u001b[39m\"\u001b[39m], _ \u001b[39m=\u001b[39m fractal_higuchi(rri, k_max\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    246\u001b[0m out[\u001b[39m\"\u001b[39m\u001b[39mKFD\u001b[39m\u001b[39m\"\u001b[39m], _ \u001b[39m=\u001b[39m fractal_katz(rri)\n\u001b[0;32m    247\u001b[0m out[\u001b[39m\"\u001b[39m\u001b[39mLZC\u001b[39m\u001b[39m\"\u001b[39m], _ \u001b[39m=\u001b[39m complexity_lempelziv(rri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\complexity\\fractal_higuchi.py:93\u001b[0m, in \u001b[0;36mfractal_higuchi\u001b[1;34m(signal, k_max, show, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     k_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, k_max \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[39m# Compute Higuchi\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     slope, intercept, info \u001b[39m=\u001b[39m _complexity_k_slope(k_max, signal)\n\u001b[0;32m     94\u001b[0m     k_values \u001b[39m=\u001b[39m info[\u001b[39m\"\u001b[39m\u001b[39mk_values\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     95\u001b[0m     average_values \u001b[39m=\u001b[39m info[\u001b[39m\"\u001b[39m\u001b[39maverage_values\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\neurokit2\\complexity\\optim_complexity_k.py:154\u001b[0m, in \u001b[0;36m_complexity_k_slope\u001b[1;34m(kmax, signal, k_number)\u001b[0m\n\u001b[0;32m    151\u001b[0m average_values \u001b[39m=\u001b[39m vectorized_Lk(k_values, signal)\n\u001b[0;32m    153\u001b[0m \u001b[39m# Slope of best-fit line through points (slope equal to FD)\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m slope, intercept \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39;49mpolyfit(np\u001b[39m.\u001b[39;49mlog(k_values), np\u001b[39m.\u001b[39;49mlog(average_values), \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m slope, intercept, {\u001b[39m\"\u001b[39m\u001b[39mk_values\u001b[39m\u001b[39m\"\u001b[39m: k_values, \u001b[39m\"\u001b[39m\u001b[39maverage_values\u001b[39m\u001b[39m\"\u001b[39m: average_values}\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py:668\u001b[0m, in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    666\u001b[0m scale \u001b[39m=\u001b[39m NX\u001b[39m.\u001b[39msqrt((lhs\u001b[39m*\u001b[39mlhs)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m    667\u001b[0m lhs \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m scale\n\u001b[1;32m--> 668\u001b[0m c, resids, rank, s \u001b[39m=\u001b[39m lstsq(lhs, rhs, rcond)\n\u001b[0;32m    669\u001b[0m c \u001b[39m=\u001b[39m (c\u001b[39m.\u001b[39mT\u001b[39m/\u001b[39mscale)\u001b[39m.\u001b[39mT  \u001b[39m# broadcast scale coefficients\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[39m# warn on rank reduction, which indicates an ill conditioned matrix\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:2300\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(a, b, rcond)\u001b[0m\n\u001b[0;32m   2297\u001b[0m \u001b[39mif\u001b[39;00m n_rhs \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2298\u001b[0m     \u001b[39m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[0;32m   2299\u001b[0m     b \u001b[39m=\u001b[39m zeros(b\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (m, n_rhs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mb\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m-> 2300\u001b[0m x, resids, rank, s \u001b[39m=\u001b[39m gufunc(a, b, rcond, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m   2301\u001b[0m \u001b[39mif\u001b[39;00m m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2302\u001b[0m     x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jortr\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:101\u001b[0m, in \u001b[0;36m_raise_linalgerror_lstsq\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_lstsq\u001b[39m(err, flag):\n\u001b[1;32m--> 101\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSVD did not converge in Linear Least Squares\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "from ECG import ECGprep\n",
    "from ECG import ECGfeatures\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'D:\\Documents\\GitHub\\EPO-4_BioBombs\\Machine learning')\n",
    "\n",
    "eda_features = np.asarray([0, 0, 0, 0], dtype=\"float\")\n",
    "\n",
    "\n",
    "# Train set\n",
    "for i in range(len(subject)):\n",
    "    obj_data = {}\n",
    "\n",
    "    obj_data[subject[i]] = read_data_of_one_subject(data_set_path, subject[i])\n",
    "    # print(obj_data[subject[i]].data)\n",
    "    chest_data_dict = obj_data[subject[i]].get_chest_data()\n",
    "\n",
    "    labels = obj_data[subject[i]].get_labels()\n",
    "    baseline = np.asarray([idx for idx, val in enumerate(labels) if val == 1])\n",
    "    stress = np.asarray([idx for idx, val in enumerate(labels) if val == 2])\n",
    "\n",
    "    ecg_stress = chest_data_dict['ECG'][stress, 0]\n",
    "    ecg_base = chest_data_dict['ECG'][baseline, 0]\n",
    "\n",
    "    fs = 700\n",
    "    # cut a smaller window\n",
    "    t_tot = (len(stress)//(int(0.5*60*fs)))\n",
    "    ecg_stress_tot = np.empty([21000, t_tot])\n",
    "    ecg_base_tot = np.empty([21000, t_tot])\n",
    "\n",
    "    for i in range(t_tot):\n",
    "        ecg1 = ecg_stress[i*int(0.5*60*700):(i+1)*int(0.5*60*700)]\n",
    "        ecg2 = ecg_base[i*int(0.5*60*700):(i+1)*int(0.5*60*700)]\n",
    "        t1 = np.arange(0, ecg1.size*(1/fs), (1/fs))\n",
    "        t1 = t1[:ecg1.size]\n",
    "        t2 = np.arange(0, ecg2.size*(1/fs), (1/fs))\n",
    "        t2 = t2[:ecg2.size]\n",
    "        ecg_stress_tot[:, i] = ecg1\n",
    "        ecg_base_tot[:, i] = ecg2\n",
    "\n",
    "    # print(eda2.shape)\n",
    "    # print(eda_stress_tot.shape)\n",
    "\n",
    "    ecg_filt_b = np.zeros((7000, t_tot))\n",
    "    ecg_filt_s = np.zeros((7000, t_tot))\n",
    "    ECG_base = []\n",
    "    ECG_stress = []\n",
    "\n",
    "    for i in range(t_tot):\n",
    "        ECG_base = ECGprep(fs, ecg_base_tot[:, i], \"baseline\")\n",
    "        ECG_stress = ECGprep(fs, ecg_stress_tot[:, i], \"stress\")\n",
    "\n",
    "        ecg_filt_b[:,i] = ECG_base.filtering_data()\n",
    "        ecg_filt_s[:,i] = ECG_stress.filtering_data()\n",
    "\n",
    "    ECG_feat_base = []\n",
    "    ECG_feat_stress = []\n",
    "\n",
    "    # peaks_b = np.zeros((7000, t_tot))\n",
    "    # peaks_s = np.zeros((7000, t_tot))\n",
    "\n",
    "    for i in range(t_tot):\n",
    "        ECG_feat_base = ECGfeatures(ecg_filt_b[:,i], fs, \"baseline\")\n",
    "        ECG_feat_stress = ECGfeatures(ecg_filt_s[:,i], fs, \"stress\")\n",
    "\n",
    "        peaks_b, info = ECG_feat_base.rpeaks()\n",
    "        peaks_s, info = ECG_feat_stress.rpeaks()\n",
    "        hrv_b= ECG_feat_base.HRV(peaks_b, fs)\n",
    "        hrv_s= ECG_feat_stress.HRV(peaks_s, fs)\n",
    "\n",
    "        # eda_features = np.vstack((ecg_features,ecg_feat_s))\n",
    "        # eda_features = np.vstack((ecg_features,ecg_feat_b))\n",
    "\n",
    "print(ecg1.shape, ecg_stress_tot.shape)\n",
    "print('\\n')\n",
    "print(np.shape(ecg_filt_b), np.shape(ecg_filt_s))\n",
    "print('\\n')\n",
    "print(type(ECG_feat_base))\n",
    "#print(np.shape(ecg_feat_b), np.shape(ecg_feat_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
