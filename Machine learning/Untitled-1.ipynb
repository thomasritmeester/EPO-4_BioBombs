{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, iirnotch, lfilter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "\n",
    "#S2 is Test data set, the other 14 will be used as training\n",
    "data_set_path = \"D:\\Downloads\\WESAD\\WESAD\\\\\"\n",
    "subject = [\"S2\",'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17']\n",
    "\n",
    "class read_data_of_one_subject:\n",
    "    \"\"\"Read data from WESAD dataset\"\"\"\n",
    "    def __init__(self, path, subject):\n",
    "        self.keys = ['label', 'subject', 'signal']\n",
    "        self.signal_keys = ['wrist', 'chest']\n",
    "        self.chest_sensor_keys = ['ACC', 'ECG', 'EDA', 'EMG', 'Resp', 'Temp']\n",
    "        self.wrist_sensor_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        #os.chdir(path)\n",
    "        #os.chdir(subject)\n",
    "        with open(path + subject +'/'+subject + '.pkl', 'rb') as file:\n",
    "            data = pickle.load(file, encoding='latin1')\n",
    "        self.data = data\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.data[self.keys[0]]\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        #label = self.data[self.keys[0]]\n",
    "        assert subject == self.data[self.keys[1]]\n",
    "        signal = self.data[self.keys[2]]\n",
    "        wrist_data = signal[self.signal_keys[0]]\n",
    "        #wrist_ACC = wrist_data[self.wrist_sensor_keys[0]]\n",
    "        #wrist_ECG = wrist_data[self.wrist_sensor_keys[1]]\n",
    "        return wrist_data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        signal = self.data[self.keys[2]]\n",
    "        chest_data = signal[self.signal_keys[1]]\n",
    "        return chest_data\n",
    "    \n",
    "\n",
    "print(len(subject))\n",
    "fs = 700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import chirp, find_peaks, peak_widths, peak_prominences\n",
    "#peaks_2d=np.empty((9,t_tot))\n",
    "#heights_2d=np.empty((5,t_tot))\n",
    "#widths_2d=np.empty((5,t_tot))\n",
    "\n",
    "def calc_phasic_data(phasic, peak, height):\n",
    "  ##Find all the points on the plot below the 50% of the peak\n",
    "  half_points = np.where(((phasic - (phasic[peak] - 0.5*height) < 0.00001)))[0]\n",
    "\n",
    "  ##Finds the index of the point directly to the right of the peak\n",
    "  half_amp_index = np.inf\n",
    "  for j in half_points:\n",
    "    if(j < half_amp_index and j > peak):\n",
    "      half_amp_index = j\n",
    "\n",
    "  \n",
    "\n",
    "  ##Calculate onset and offset\n",
    "  onset_points = np.where(((phasic - (phasic[peak] - 0.63*height) < 0.00001)))[0]\n",
    "\n",
    "  ##Finds the index of the point directly to the right of the peak\n",
    "  offset_amp_index = np.inf\n",
    "  for j in onset_points:\n",
    "    if(j < offset_amp_index and j > peak):\n",
    "      offset_amp_index = j\n",
    "\n",
    "  ##Finds the index of the point directly to the right of the peak\n",
    "  onset_amp_index = 0\n",
    "  for j in onset_points:\n",
    "    if(j > onset_amp_index and j < peak):\n",
    "      onset_amp_index = j\n",
    "\n",
    "  \n",
    "\n",
    "  return onset_amp_index, half_amp_index, offset_amp_index\n",
    "\n",
    "\n",
    "def calc_phasic_features(phasic, t_tot, state):\n",
    "  \n",
    "  temp_array = np.asarray([], dtype = \"float\")\n",
    "\n",
    "\n",
    "  orienting_mag = np.asarray([], dtype = \"float\")\n",
    "  orienting_time = np.asarray([], dtype = \"float\")\n",
    "  half_recov_time = np.asarray([], dtype = \"float\")\n",
    "\n",
    "  peaks, _ = find_peaks(phasic)\n",
    "  heights, _, __ = peak_prominences(phasic, peaks)\n",
    "  widths, _, __, ___ = peak_widths(phasic, peaks, rel_height=0.63)\n",
    "\n",
    "  # find the indices with an amplitude larger that 0.1\n",
    "  keep = np.full(len(peaks), True)\n",
    "  keep[peaks < 0.1] = False\n",
    "\n",
    "  # only keep those\n",
    "  peaks=peaks[keep]\n",
    "  heights=heights[keep]\n",
    "  widths=widths[keep]\n",
    "\n",
    "  # peaks=np.hstack(peaks)\n",
    "  # heights=np.hstack(heights)\n",
    "  # widths=np.hstack(widths)\n",
    "\n",
    "  for i in range(len(peaks)):\n",
    "    onset_amp_index, half_amp_index, offset_amp_index = calc_phasic_data(phasic, peaks[i], heights[i])\n",
    "    \n",
    "    orienting_mag = np.append(orienting_mag, phasic[peaks[i]] - phasic[onset_amp_index])\n",
    "    orienting_time = np.append(orienting_time, (offset_amp_index - onset_amp_index)/fs)\n",
    "    half_recov_time = np.append(half_recov_time, (half_amp_index - peaks[i])/fs)\n",
    "\n",
    "  cv_mg = np.std(orienting_mag)/np.mean(orienting_mag)\n",
    "  cv_orient = np.std(orienting_time)/np.mean(orienting_time)\n",
    "  cv_recov = np.std(half_recov_time)/np.mean(half_recov_time)\n",
    "\n",
    "  temp_array = np.append(temp_array, cv_mg)\n",
    "  temp_array = np.append(temp_array, cv_orient)\n",
    "  temp_array = np.append(temp_array, cv_recov)\n",
    "\n",
    "  if(state == False):\n",
    "    temp_array = np.append(temp_array,0)\n",
    "  else:\n",
    "    temp_array = np.append(temp_array,1)\n",
    "\n",
    "\n",
    "  #print(temp_array)\n",
    "\n",
    "  \n",
    "  return temp_array\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 4)\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.92964439 1.13884068 0.73774784 1.        ]\n",
      " [1.44666709 0.69990238 0.73262802 0.        ]\n",
      " ...\n",
      " [0.91781103 0.83295579 0.51002204 0.        ]\n",
      " [1.26342398 0.88448181 0.92819614 1.        ]\n",
      " [1.3267998  0.7212378  0.80955186 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from EDA import EDAprep\n",
    "import sys\n",
    "sys.path.insert(1, 'D:\\Documents\\GitHub\\EPO-4_BioBombs\\Machine learning')\n",
    "\n",
    "eda_features = np.asarray([0,0,0,0], dtype = \"float\")\n",
    " \n",
    "\n",
    "#Train set\n",
    "for i in range(len(subject)):\n",
    "    obj_data = {}\n",
    "\n",
    "    obj_data[subject[i]] = read_data_of_one_subject(data_set_path, subject[i])\n",
    "    #print(obj_data[subject[i]].data)\n",
    "    chest_data_dict = obj_data[subject[i]].get_chest_data()\n",
    "\n",
    "    labels = obj_data[subject[i]].get_labels() \n",
    "    baseline = np.asarray([idx for idx,val in enumerate(labels) if val == 1])\n",
    "    stress = np.asarray([idx for idx,val in enumerate(labels) if val == 2])\n",
    "\n",
    "    eda_stress=chest_data_dict['EDA'][stress,0]\n",
    "    eda_base=chest_data_dict['EDA'][baseline,0]\n",
    "\n",
    "    fs=700\n",
    "    # cut a smaller window\n",
    "    t_tot=(len(stress)//(int(0.5*60*fs)))\n",
    "    eda_stress_tot=np.empty([21000,t_tot])\n",
    "    eda_base_tot=np.empty([21000,t_tot])\n",
    "\n",
    "    for i in range(t_tot): \n",
    "        eda1=eda_stress[i*int(0.5*60*700):(i+1)*int(0.5*60*700)]\n",
    "        eda2=eda_base[i*int(0.5*60*700):(i+1)*int(0.5*60*700)]\n",
    "        t1=np.arange(0,eda1.size*(1/fs),(1/fs))\n",
    "        t1=t1[:eda1.size]\n",
    "        t2=np.arange(0,eda2.size*(1/fs),(1/fs))\n",
    "        t2=t2[:eda2.size]\n",
    "        eda_stress_tot[:,i] = eda1\n",
    "        eda_base_tot[:,i]=eda2\n",
    "        \n",
    "    #print(eda1.shape)\n",
    "    #print(eda_stress_tot.shape)\n",
    "\n",
    "    #print(eda2.shape)\n",
    "    #print(eda_stress_tot.shape)\n",
    "\n",
    "    eda_comp_base=np.zeros((3,11000,t_tot))\n",
    "    eda_comp_stress=np.zeros((3,11000,t_tot))\n",
    "    EDA_base = []\n",
    "    EDA_stress = []\n",
    "    for i in range (t_tot): \n",
    "        EDA_base = EDAprep(fs, eda_base_tot[:,i],t_tot,\"baseline\")\n",
    "        EDA_stress = EDAprep(fs, eda_stress_tot[:,i],t_tot,\"stress\")\n",
    "\n",
    "        #EDA.plotdata()\n",
    "        eda_lp = EDA_base.filtering_data()\n",
    "        eda_sm = EDA_base.smoothing_data(eda_lp)\n",
    "        eda_comp_base[:,:,i]=EDA_base.decompose_data(eda_sm)\n",
    "\n",
    "        eda_lp = EDA_stress.filtering_data()\n",
    "        eda_sm = EDA_stress.smoothing_data(eda_lp)\n",
    "        eda_comp_stress[:,:,i]=EDA_stress.decompose_data(eda_sm)\n",
    "    \n",
    "        phasic_base = eda_comp_base[1][:,i]\n",
    "        phasic_stress = eda_comp_stress[1][:,i]\n",
    "\n",
    "        t=np.arange(0,phasic_stress.size*(1/fs),(1/fs))\n",
    "        t=t[:phasic_stress.shape[0]]\n",
    "\n",
    "        # plt.figure(figsize=(12,4))\n",
    "        # plt.xlim([0,30])\n",
    "        # plt.plot(t,phasic_stress,label='phasic')\n",
    "        # plt.xlabel('$Time (s)$') \n",
    "        # plt.ylabel('$EDA$') \n",
    "        # plt.legend()\n",
    "\n",
    "        #print((phasic_stress[0:10]))\n",
    "\n",
    "        #For the state, True is stress and False is base\n",
    "        \n",
    "        \n",
    "        stress_feature = calc_phasic_features(phasic_stress, t_tot, True)\n",
    "        np.reshape(stress_feature, (1,-1))\n",
    "        base_features = calc_phasic_features(phasic_base, t_tot, False)\n",
    "\n",
    "        \n",
    "        \n",
    "        eda_features = np.vstack((eda_features,stress_feature))\n",
    "        eda_features = np.vstack((eda_features,calc_phasic_features(phasic_base, t_tot, False)))\n",
    "\n",
    "\n",
    "print(np.shape(eda_features))\n",
    "print(eda_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "0.6805555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_in = eda_features[1:,0:3]\n",
    "stress_state = eda_features[1:,3:4]\n",
    "stress_state = np.ravel(stress_state)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_in, stress_state, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "lda=LDA(n_components=1)\n",
    "train_lda=lda.fit(X_train, y_train)\n",
    "test_lda=lda.predict(X_test)\n",
    "\n",
    "print(test_lda)\n",
    "print(y_test)\n",
    "\n",
    "print(sum(test_lda == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
